{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy51Ha9LtJhp"
      },
      "source": [
        "# Routing Weight Optimization: Data Processing and Training Workflow\n",
        "\n",
        "This notebook runs the main workflow for the offline RL agent:\n",
        "1. **Setup:** Clones the repo (or pulls updates), installs dependencies, and sets up paths.\n",
        "2. **Data Preparation:** Runs the `create_dataset.py` script to generate the `MDPDataset`.\n",
        "3. **Model Training:** Runs the `train_cql.py` script to train the CQL agent.\n",
        "4. **Basic Results:** Loads and plots some training metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7daI-1ttJhr"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   # Install GitHub CLI\n",
        "   !apt-get install -y gh\n",
        "\n",
        "   # Authenticate (this will provide an interactive web flow)\n",
        "   !gh auth login -w"
      ],
      "metadata": {
        "id": "v6BuA3xUv9YL",
        "outputId": "ede6ea9d-3104-45e0-dc4e-2e31f814198a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "gh is already the newest version (2.4.0+dfsg1-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "\n",
            "\u001b[0;33m!\u001b[0m First copy your one-time code: \u001b[0;1;39mE9CB-0481\u001b[0m\n",
            "- \u001b[0;1;39mPress Enter\u001b[0m to open github.com in your browser... \n",
            "/usr/bin/xdg-open: 882: www-browser: not found\n",
            "/usr/bin/xdg-open: 882: links2: not found\n",
            "/usr/bin/xdg-open: 882: elinks: not found\n",
            "/usr/bin/xdg-open: 882: links: not found\n",
            "/usr/bin/xdg-open: 882: lynx: not found\n",
            "/usr/bin/xdg-open: 882: w3m: not found\n",
            "xdg-open: no method available for opening 'https://github.com/login/device'\n",
            "\u001b[0;31m!\u001b[0m Failed opening a web browser at https://github.com/login/device\n",
            "  exit status 3\n",
            "  Please try entering the URL in your browser manually\n",
            "\n",
            "\n",
            "\u001b[0;32m✓\u001b[0m Authentication complete. \u001b[0;1;39mPress Enter\u001b[0m to continue...\n",
            "\u001b[0;32m✓\u001b[0m Logged in as \u001b[0;1;39msaikanam\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Install GitHub CLI (if not already installed)\n",
        "print(\"Ensuring GitHub CLI is installed...\")\n",
        "!apt-get update > /dev/null && apt-get install -y gh > /dev/null\n",
        "print(\"GitHub CLI installed.\")\n",
        "\n",
        "# Authenticate with GitHub (should use cached credentials)\n",
        "print(\"\\nAuthenticating with GitHub CLI (use cached credentials if available)...\")\n",
        "!gh auth login --hostname github.com -w\n",
        "\n",
        "# Explicitly configure git to use gh as the credential helper\n",
        "print(\"\\nConfiguring git credential helper using 'gh auth setup-git'...\")\n",
        "!gh auth setup-git\n",
        "\n",
        "# --- Attempt standard git clone AFTER configuration ---\n",
        "print(\"\\nAttempting git clone...\")\n",
        "# Define repo URL and target directory\n",
        "repo_url = \"https://github.com/saikanam/openRoad-dr-training.git\"\n",
        "target_dir = \"/content/openRoad-dr-training\"\n",
        "\n",
        "# Use standard git clone\n",
        "clone_cmd = f\"git clone {repo_url} {target_dir}\"\n",
        "!{clone_cmd} # Execute the clone command\n",
        "\n",
        "# --- Check results and change directory ---\n",
        "try:\n",
        "    # Check if the directory exists and is not empty\n",
        "    if os.path.exists(target_dir) and os.listdir(target_dir):\n",
        "        print(f\"\\nRepository seems to be cloned successfully into {target_dir}\")\n",
        "        %cd {target_dir}\n",
        "        print(f\"Current working directory: {os.getcwd()}\")\n",
        "        # List contents to verify\n",
        "        print(\"\\nListing repository contents:\")\n",
        "        !ls -al\n",
        "    else:\n",
        "        print(f\"\\nError: Cloning appears to have failed. Directory {target_dir} is missing or empty.\")\n",
        "        print(\"\\nChecking GitHub CLI auth status:\")\n",
        "        !gh auth status\n",
        "        print(\"\\nChecking git config for credential helper:\")\n",
        "        !git config --global --get credential.helper\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nError changing directory or listing contents: {e}\")\n",
        "    print(\"Please check if the repository was cloned successfully.\")"
      ],
      "metadata": {
        "id": "8cbs6Ga_yCiY",
        "outputId": "8dfb533b-77a7-49b8-bd4e-7cab5828538e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensuring GitHub CLI is installed...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "GitHub CLI installed.\n",
            "\n",
            "Authenticating with GitHub CLI (use cached credentials if available)...\n",
            "\n",
            "\u001b[0;33m!\u001b[0m First copy your one-time code: \u001b[0;1;39m79BD-77C3\u001b[0m\n",
            "- \u001b[0;1;39mPress Enter\u001b[0m to open github.com in your browser... "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IP6EF2OQxXSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WNTiWcHktJhs",
        "outputId": "2a50b7ea-d88a-4575-8d2a-daa88029ed86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab\n",
            "Repository openRoad-dr-training already exists in /content. Pulling latest changes...\n",
            "/content/openRoad-dr-training\n",
            "From https://github.com/saikanam/openRoad-dr-training\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "\n",
            "Current directory: /content/openRoad-dr-training\n"
          ]
        }
      ],
      "source": [
        "# === Google Colab Setup ===\n",
        "# Clone the repository (if not already done) and pull latest changes\n",
        "\n",
        "import os\n",
        "\n",
        "REPO_NAME = \"openRoad-dr-training\" # Your repository name\n",
        "# Use HTTPS URL for easier public/token access in Colab by default\n",
        "# You might need to generate a Personal Access Token (PAT) on GitHub\n",
        "# and use it in the URL like: https://<YOUR_PAT>@github.com/saikanam/openRoad-dr-training.git\n",
        "# Or configure SSH keys if you prefer.\n",
        "REPO_URL_HTTPS = \"https://github.com/saikanam/openRoad-dr-training.git\"\n",
        "\n",
        "# Check if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"Running in Google Colab\")\n",
        "    # Check if repo already exists in Colab's /content directory\n",
        "    colab_repo_path = f\"/content/{REPO_NAME}\"\n",
        "    if not os.path.exists(colab_repo_path):\n",
        "        print(f\"Cloning repository: {REPO_URL_HTTPS} into {colab_repo_path}\")\n",
        "        # Clone using HTTPS\n",
        "        !git clone {REPO_URL_HTTPS} {colab_repo_path}\n",
        "        %cd {colab_repo_path}\n",
        "    else:\n",
        "        print(f\"Repository {REPO_NAME} already exists in /content. Pulling latest changes...\")\n",
        "        %cd {colab_repo_path}\n",
        "        !git pull origin main\n",
        "else:\n",
        "    # Assume running locally, repository is the current directory\n",
        "    print(\"Running locally, repository assumed to be current directory.\")\n",
        "    # Optionally, you could still run git pull here if desired\n",
        "    # !git pull origin main\n",
        "    pass\n",
        "\n",
        "print(f\"\\nCurrent directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Fvlf8YSdtJhu",
        "outputId": "b27769ff-b0e7-4a92-c025-074722a9faea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies from requirements.txt...\n",
            "Collecting d3rlpy==2.8.1 (from -r requirements.txt (line 1))\n",
            "  Using cached d3rlpy-2.8.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pandas==2.2.3 (from -r requirements.txt (line 2))\n",
            "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting numpy==1.26.2 (from -r requirements.txt (line 3))\n",
            "  Using cached numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scikit-learn==1.3.2 (from -r requirements.txt (line 4))\n",
            "  Using cached scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting joblib==1.3.2 (from -r requirements.txt (line 5))\n",
            "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting torch>=2.5.0 (from d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting tqdm>=4.66.3 (from d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py (from d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting gym>=0.26.0 (from d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached gym-0.26.2-py3-none-any.whl\n",
            "Collecting click (from d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting typing-extensions (from d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting structlog (from d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached structlog-25.2.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting colorama (from d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting dataclasses-json (from d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting gymnasium==1.0.0 (from d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas==2.2.3->-r requirements.txt (line 2))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas==2.2.3->-r requirements.txt (line 2))\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas==2.2.3->-r requirements.txt (line 2))\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting scipy>=1.5.0 (from scikit-learn==1.3.2->-r requirements.txt (line 4))\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn==1.3.2->-r requirements.txt (line 4))\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting cloudpickle>=1.2.0 (from gymnasium==1.0.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium==1.0.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting gym_notices>=0.0.4 (from gym>=0.26.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 2))\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting filelock (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting networkx (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting packaging>=17.0 (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.5.0->d3rlpy==2.8.1->-r requirements.txt (line 1))\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Using cached d3rlpy-2.8.1-py3-none-any.whl (201 kB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Using cached numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Using cached scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "Using cached gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached structlog-25.2.0-py3-none-any.whl (68 kB)\n",
            "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
            "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, pytz, nvidia-cusparselt-cu12, mpmath, gym_notices, farama-notifications, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, structlog, six, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, mypy-extensions, MarkupSafe, joblib, fsspec, filelock, colorama, cloudpickle, click, typing-inspect, scipy, python-dateutil, nvidia-cusparse-cu12, nvidia-cudnn-cu12, marshmallow, jinja2, h5py, gymnasium, gym, scikit-learn, pandas, nvidia-cusolver-cu12, dataclasses-json, torch, d3rlpy\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: gym_notices\n",
            "    Found existing installation: gym-notices 0.0.8\n",
            "    Uninstalling gym-notices-0.0.8:\n",
            "      Successfully uninstalled gym-notices-0.0.8\n",
            "  Attempting uninstall: farama-notifications\n",
            "    Found existing installation: Farama-Notifications 0.0.4\n",
            "    Uninstalling Farama-Notifications-0.0.4:\n",
            "      Successfully uninstalled Farama-Notifications-0.0.4\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.1\n",
            "    Uninstalling typing_extensions-4.13.1:\n",
            "      Successfully uninstalled typing_extensions-4.13.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.6.0\n",
            "    Uninstalling threadpoolctl-3.6.0:\n",
            "      Successfully uninstalled threadpoolctl-3.6.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: structlog\n",
            "    Found existing installation: structlog 25.2.0\n",
            "    Uninstalling structlog-25.2.0:\n",
            "      Successfully uninstalled structlog-25.2.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.2\n",
            "    Uninstalling numpy-1.26.2:\n",
            "      Successfully uninstalled numpy-1.26.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: mypy-extensions\n",
            "    Found existing installation: mypy-extensions 1.0.0\n",
            "    Uninstalling mypy-extensions-1.0.0:\n",
            "      Successfully uninstalled mypy-extensions-1.0.0\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.3.2\n",
            "    Uninstalling joblib-1.3.2:\n",
            "      Successfully uninstalled joblib-1.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: colorama\n",
            "    Found existing installation: colorama 0.4.6\n",
            "    Uninstalling colorama-0.4.6:\n",
            "      Successfully uninstalled colorama-0.4.6\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: typing-inspect\n",
            "    Found existing installation: typing-inspect 0.9.0\n",
            "    Uninstalling typing-inspect-0.9.0:\n",
            "      Successfully uninstalled typing-inspect-0.9.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: marshmallow\n",
            "    Found existing installation: marshmallow 3.26.1\n",
            "    Uninstalling marshmallow-3.26.1:\n",
            "      Successfully uninstalled marshmallow-3.26.1\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.13.0\n",
            "    Uninstalling h5py-3.13.0:\n",
            "      Successfully uninstalled h5py-3.13.0\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.0.0\n",
            "    Uninstalling gymnasium-1.0.0:\n",
            "      Successfully uninstalled gymnasium-1.0.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.26.2\n",
            "    Uninstalling gym-0.26.2:\n",
            "      Successfully uninstalled gym-0.26.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.3.2\n",
            "    Uninstalling scikit-learn-1.3.2:\n",
            "      Successfully uninstalled scikit-learn-1.3.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: dataclasses-json\n",
            "    Found existing installation: dataclasses-json 0.6.7\n",
            "    Uninstalling dataclasses-json-0.6.7:\n",
            "      Successfully uninstalled dataclasses-json-0.6.7\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: d3rlpy\n",
            "    Found existing installation: d3rlpy 2.8.1\n",
            "    Uninstalling d3rlpy-2.8.1:\n",
            "      Successfully uninstalled d3rlpy-2.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 click-8.1.8 cloudpickle-3.1.1 colorama-0.4.6 d3rlpy-2.8.1 dataclasses-json-0.6.7 farama-notifications-0.0.4 filelock-3.18.0 fsspec-2025.3.2 gym-0.26.2 gym_notices-0.0.8 gymnasium-1.0.0 h5py-3.13.0 jinja2-3.1.6 joblib-1.3.2 marshmallow-3.26.1 mpmath-1.3.0 mypy-extensions-1.0.0 networkx-3.4.2 numpy-1.26.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 packaging-24.2 pandas-2.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 scikit-learn-1.3.2 scipy-1.15.2 six-1.17.0 structlog-25.2.0 sympy-1.13.1 threadpoolctl-3.6.0 torch-2.6.0 tqdm-4.67.1 triton-3.2.0 typing-extensions-4.13.1 typing-inspect-0.9.0 tzdata-2025.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "pytz",
                  "six"
                ]
              },
              "id": "4b7fdda5550c4a09b24626da7985352b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# === Install Dependencies ===\n",
        "print(\"Installing dependencies from requirements.txt...\")\n",
        "!pip install -r requirements.txt --force"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "P9pIEi0stJhu",
        "outputId": "88e74c58-25d7-4071-a5a5-c5dce255f1de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-ece62299062a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# === Imports and Path Definitions ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) from _err\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"warn_copy_on_write\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from pandas._config.config import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "# === Imports and Path Definitions ===\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import d3rlpy # Verify import after install\n",
        "\n",
        "# Define relative paths (should work relative to repo root)\n",
        "DATA_INPUT_DIR = \"training_data\" # Relative path from create_dataset.py default\n",
        "DATA_OUTPUT_DIR = \"data\"\n",
        "DATASET_FILENAME = \"routing_dataset.h5\"\n",
        "DATASET_PATH = os.path.join(DATA_OUTPUT_DIR, DATASET_FILENAME)\n",
        "SCALER_PATH = os.path.join(DATA_OUTPUT_DIR, \"state_scaler.pkl\")\n",
        "LOG_DIR = \"d3rlpy_logs\"\n",
        "\n",
        "# Ensure output directories exist\n",
        "os.makedirs(DATA_OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Dataset will be saved to: {DATASET_PATH}\")\n",
        "print(f\"Scaler will be saved to: {SCALER_PATH}\")\n",
        "print(f\"Training logs will be saved in: {LOG_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jngQCyU2tJhv"
      },
      "source": [
        "## 2. Data Preparation\n",
        "\n",
        "Run the script to process the raw CSV data into the `MDPDataset` format required by d3rlpy. This assumes the `training_data` directory exists at the root of the repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_efbFzFxtJhw"
      },
      "outputs": [],
      "source": [
        "# === Run Data Creation Script ===\n",
        "# Note: This assumes the 'training_data' folder is present in the root\n",
        "# of the repository when cloned. It's not tracked by Git currently.\n",
        "\n",
        "if not os.path.exists(DATA_INPUT_DIR):\n",
        "    print(f\"Warning: Input data directory '{DATA_INPUT_DIR}' not found. \\n\",\n",
        "          f\"Please ensure it exists in the repository root ('{os.getcwd()}') before running this step.\")\n",
        "else:\n",
        "    print(f\"Running data creation script... Input: {DATA_INPUT_DIR}, Output Dir: {DATA_OUTPUT_DIR}\")\n",
        "    !python src/data_processing/create_dataset.py --input_dir {DATA_INPUT_DIR} --output_dir {DATA_OUTPUT_DIR} --output_filename {DATASET_FILENAME}\n",
        "\n",
        "    # === Verify Output ===\n",
        "    if os.path.exists(DATASET_PATH):\n",
        "        print(f\"\\nDataset file created successfully at: {DATASET_PATH}\")\n",
        "    else:\n",
        "        print(f\"\\nError: Dataset file not found at {DATASET_PATH}. Check script output above.\")\n",
        "\n",
        "    if os.path.exists(SCALER_PATH):\n",
        "        print(f\"State scaler file created successfully at: {SCALER_PATH}\")\n",
        "    else:\n",
        "        print(f\"Error: State scaler file not found at {SCALER_PATH}. Check script output above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnF8oo9dtJhw"
      },
      "source": [
        "## 3. Model Training\n",
        "\n",
        "Run the training script using the generated dataset. Adjust hyperparameters as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1Ij3EgNtJhx"
      },
      "outputs": [],
      "source": [
        "# === Training Configuration ===\n",
        "# Using parameters that showed some promise previously (low LR, low alpha, no reward scaling)\n",
        "EXPERIMENT_NAME = \"CQL_Colab_Run_v3\" # Increment experiment name\n",
        "CONSERVATIVE_WEIGHT = 1.0\n",
        "ACTOR_LR = 1e-6\n",
        "CRITIC_LR = 1e-6\n",
        "EPOCHS = 50 # Adjust as needed\n",
        "USE_REWARD_SCALER_FLAG = \"--no-use_reward_scaler\" # Use '--use_reward_scaler' to enable\n",
        "DEVICE_FLAG = \"--use_gpu\" # Use '--use_cpu' if no GPU available in Colab\n",
        "SEED = 42 # Set a random seed for reproducibility\n",
        "\n",
        "# === Run Training Script ===\n",
        "print(f\"Starting training run: {EXPERIMENT_NAME}\")\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    print(f\"Error: Dataset file not found at {DATASET_PATH}. Cannot start training.\")\n",
        "else:\n",
        "    !python src/training/train_cql.py \\\n",
        "        --dataset {DATASET_PATH} \\\n",
        "        --experiment_name {EXPERIMENT_NAME} \\\n",
        "        --conservative_weight {CONSERVATIVE_WEIGHT} \\\n",
        "        --actor_lr {ACTOR_LR} \\\n",
        "        --critic_lr {CRITIC_LR} \\\n",
        "        --epochs {EPOCHS} \\\n",
        "        --seed {SEED} \\\n",
        "        {USE_REWARD_SCALER_FLAG} \\\n",
        "        {DEVICE_FLAG}\n",
        "        # Add other arguments as needed\n",
        "\n",
        "    print(f\"\\nTraining finished. Logs should be available in: {os.path.join(LOG_DIR, EXPERIMENT_NAME)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb9LjcNdtJhx"
      },
      "source": [
        "## 4. Basic Results\n",
        "\n",
        "Load and plot some basic training metrics from the logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cUb8JLNtJhy"
      },
      "outputs": [],
      "source": [
        "# === Load Logs ===\n",
        "# Use the experiment name defined in the training cell\n",
        "log_path = os.path.join(LOG_DIR, EXPERIMENT_NAME)\n",
        "metrics_to_plot = [\n",
        "    \"critic_loss\", \"actor_loss\", \"temp_loss\", \"alpha_loss\",\n",
        "    \"conservative_loss\", \"td_error\", \"initial_state_value\",\n",
        "    \"temperature\", \"alpha\" # Include temp and alpha if available\n",
        "]\n",
        "\n",
        "metrics_data = {}\n",
        "print(f\"Attempting to load logs from: {log_path}\")\n",
        "\n",
        "if os.path.exists(log_path):\n",
        "    for metric in metrics_to_plot:\n",
        "        csv_path = os.path.join(log_path, f\"{metric}.csv\")\n",
        "        if os.path.exists(csv_path):\n",
        "            try:\n",
        "                metrics_data[metric] = pd.read_csv(csv_path)\n",
        "                print(f\"  Loaded {metric}.csv\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error loading {metric}.csv: {e}\")\n",
        "        else:\n",
        "            # Don't print missing for optional ones like temp/alpha\n",
        "            if metric not in ['temperature', 'alpha']:\n",
        "                 print(f\"  {metric}.csv not found.\")\n",
        "else:\n",
        "    print(f\"Log directory not found: {log_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6reZTAJtJhy"
      },
      "outputs": [],
      "source": [
        "# === Plot Metrics ===\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "num_metrics = len(metrics_data)\n",
        "\n",
        "if num_metrics > 0:\n",
        "    # Determine grid size (e.g., 3 columns)\n",
        "    ncols = 3\n",
        "    nrows = (num_metrics + ncols - 1) // ncols\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18, 5 * nrows), squeeze=False)\n",
        "    axes = axes.flatten() # Flatten to easily iterate\n",
        "\n",
        "    plot_idx = 0\n",
        "    for metric, df in metrics_data.items():\n",
        "        if not df.empty:\n",
        "            ax = axes[plot_idx]\n",
        "            if 'step' in df.columns and 'value' in df.columns:\n",
        "                sns.lineplot(data=df, x='step', y='value', ax=ax)\n",
        "                ax.set_title(f\"{metric} vs. Training Step\")\n",
        "                ax.set_xlabel(\"Training Step\")\n",
        "                ax.set_ylabel(metric.replace('_', ' ').title())\n",
        "            else:\n",
        "                ax.set_title(f\"{metric} - Data Missing Columns\")\n",
        "            plot_idx += 1\n",
        "\n",
        "    # Hide unused subplots\n",
        "    for i in range(plot_idx, len(axes)):\n",
        "        axes[i].set_visible(False)\n",
        "\n",
        "    plt.tight_layout(pad=3.0)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No metric data loaded to plot.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}